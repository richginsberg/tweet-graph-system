# Local Environment Configuration
# Copy this to .env and fill in your values

# ===========================================
# Docker Compose Configuration
# ===========================================

# Neo4j Password (change for production!)
NEO4J_PASSWORD=tweetgraph123

# ===========================================
# X/Twitter Bookmark Fetcher Configuration
# ===========================================

# Fetch mode: browser | api | hybrid
# - browser: Browser scraping only (marks truncated tweets)
# - api: X API v2 only (low usage, requires X_BEARER_TOKEN)
# - hybrid: Browser + API to fix truncated tweets (recommended)
FETCH_MODE=browser

# X API v2 credentials (required for api/hybrid modes)
# Also used by API to enrich truncated tweets on sync
# Get from: https://developer.twitter.com/en/portal/dashboard
TWITTER_BEARER_TOKEN=

# X API tier: free | basic | pro
# - free: Write-only, enrichment disabled
# - basic: Limited reads ($100/mo), enrichment enabled
# - pro: Full access ($5000/mo)
# If unset or "free", enrich button is hidden in UI
TWITTER_API_TIER=free

# Truncation detection (comma-separated indicators)
TRUNCATION_INDICATORS=â€¦,>>>,[more]

# ===========================================
# Embedding Provider Configuration
# ===========================================

# === OpenAI (Default) ===
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=sk-your-openai-key
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536

# === DeepInfra ===
# EMBEDDING_PROVIDER=deepinfra
# EMBEDDING_API_KEY=your-deepinfra-key
# EMBEDDING_MODEL=BAAI/bge-base-en-v1.5
# EMBEDDING_DIMENSIONS=768

# === Chutes.ai (8B model - high quality) ===
# EMBEDDING_PROVIDER=chutes-8b
# EMBEDDING_API_KEY=your-chutes-api-token
# EMBEDDING_MODEL=qwen3-embedding-8b
# EMBEDDING_DIMENSIONS=4096

# === Chutes.ai (0.6B model - fast) ===
# EMBEDDING_PROVIDER=chutes-0.6b
# EMBEDDING_API_KEY=your-chutes-api-token
# EMBEDDING_MODEL=qwen3-embedding-0.6b
# EMBEDDING_DIMENSIONS=1024

# === DeepSeek ===
# EMBEDDING_PROVIDER=deepseek
# EMBEDDING_API_KEY=your-deepseek-key
# EMBEDDING_MODEL=deepseek-embed
# EMBEDDING_DIMENSIONS=1536

# === Together AI ===
# EMBEDDING_PROVIDER=together
# EMBEDDING_API_KEY=your-together-key
# EMBEDDING_MODEL=togethercomputer/m2-bert-80M-8k-retrieval
# EMBEDDING_DIMENSIONS=768

# === Groq ===
# EMBEDDING_PROVIDER=groq
# EMBEDDING_API_KEY=your-groq-key
# EMBEDDING_MODEL=nomic-embed-text-v1
# EMBEDDING_DIMENSIONS=768

# === Ollama (Local) ===
# EMBEDDING_PROVIDER=ollama
# EMBEDDING_API_BASE=http://host.docker.internal:11434/v1
# EMBEDDING_MODEL=nomic-embed-text
# EMBEDDING_DIMENSIONS=768

# === Local/Custom ===
# EMBEDDING_PROVIDER=custom
# EMBEDDING_API_BASE=http://your-server:8000/v1
# EMBEDDING_API_KEY=your-key
# EMBEDDING_MODEL=your-model
# EMBEDDING_DIMENSIONS=1536
