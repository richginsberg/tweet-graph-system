# Local Environment Configuration
# Copy this to .env and fill in your values

# ===========================================
# Embedding Provider Configuration
# ===========================================

# === OpenAI (Default) ===
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=sk-your-openai-key
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536

# === DeepInfra ===
# EMBEDDING_PROVIDER=deepinfra
# EMBEDDING_API_KEY=your-deepinfra-key
# EMBEDDING_MODEL=BAAI/bge-base-en-v1.5
# EMBEDDING_DIMENSIONS=768

# === Chutes.ai (8B model - high quality) ===
# EMBEDDING_PROVIDER=chutes-8b
# EMBEDDING_API_KEY=your-chutes-api-token
# EMBEDDING_MODEL=qwen3-embedding-8b
# EMBEDDING_DIMENSIONS=4096

# === Chutes.ai (0.6B model - fast) ===
# EMBEDDING_PROVIDER=chutes-0.6b
# EMBEDDING_API_KEY=your-chutes-api-token
# EMBEDDING_MODEL=qwen3-embedding-0.6b
# EMBEDDING_DIMENSIONS=1024

# === DeepSeek ===
# EMBEDDING_PROVIDER=deepseek
# EMBEDDING_API_KEY=your-deepseek-key
# EMBEDDING_MODEL=deepseek-embed
# EMBEDDING_DIMENSIONS=1536

# === Together AI ===
# EMBEDDING_PROVIDER=together
# EMBEDDING_API_KEY=your-together-key
# EMBEDDING_MODEL=togethercomputer/m2-bert-80M-8k-retrieval
# EMBEDDING_DIMENSIONS=768

# === Groq ===
# EMBEDDING_PROVIDER=groq
# EMBEDDING_API_KEY=your-groq-key
# EMBEDDING_MODEL=nomic-embed-text-v1
# EMBEDDING_DIMENSIONS=768

# === Ollama (Local) ===
# EMBEDDING_PROVIDER=ollama
# EMBEDDING_API_BASE=http://host.docker.internal:11434/v1
# EMBEDDING_MODEL=nomic-embed-text
# EMBEDDING_DIMENSIONS=768

# === Local/Custom ===
# EMBEDDING_PROVIDER=custom
# EMBEDDING_API_BASE=http://your-server:8000/v1
# EMBEDDING_API_KEY=your-key
# EMBEDDING_MODEL=your-model
# EMBEDDING_DIMENSIONS=1536
